import os
import json
import gspread
from datetime import datetime, timedelta
from google.oauth2.service_account import Credentials

# âœ… èªè¨¼ï¼ˆGitHub Secretsï¼‰
service_account_info = json.loads(os.environ["GCP_SERVICE_ACCOUNT_KEY"])
creds = Credentials.from_service_account_info(
    service_account_info,
    scopes=["https://www.googleapis.com/auth/spreadsheets"]
)
gc = gspread.authorize(creds)

# âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDè¨­å®š
SOURCE_SPREADSHEET_ID = "1RglATeTbLU1SqlfXnNToJqhXLdNoHCdePldioKDQgU8"  # ãƒ‡ãƒ¼ã‚¿å…ƒï¼ˆMSN, Google, Yahooï¼‰
DEST_SPREADSHEET_ID = "1IYUuwzvlR2OJC8r3FkaUvA44tc0XGqT2kxbAXiMgt2s"    # å‡ºåŠ›å…ˆ

# âœ… æ—¥ä»˜ç¯„å›²ï¼šå‰æ—¥15:00ã€œå½“æ—¥15:00
today = datetime.now()
today_str = today.strftime("%y%m%d")
yesterday_15 = datetime(today.year, today.month, today.day, 15) - timedelta(days=1)
today_15 = datetime(today.year, today.month, today.day, 15)

# âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶š
source_book = gc.open_by_key(SOURCE_SPREADSHEET_ID)
dest_book = gc.open_by_key(DEST_SPREADSHEET_ID)

# âœ… å‡ºåŠ›å…ˆã‚·ãƒ¼ãƒˆä½œæˆï¼ˆBase ã‚’ã‚³ãƒ”ãƒ¼ â†’ æœ¬æ—¥ã®æ—¥ä»˜ã‚·ãƒ¼ãƒˆï¼‰
try:
    dest_book.del_worksheet(dest_book.worksheet(today_str))
except:
    pass

base_ws = dest_book.worksheet("Base")
target_ws = dest_book.duplicate_sheet(base_ws.id, new_sheet_name=today_str)

# âœ… ã‚½ãƒ¼ã‚¹é †ã«å‡¦ç†
SOURCE_ORDER = ["MSN", "Google", "Yahoo"]
all_rows = []

# âœ… æ—¥æ™‚ãƒ‘ãƒ¼ã‚¹é–¢æ•°ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè‡ªå‹•åˆ¤å®šï¼‰
def parse_datetime(s):
    try:
        return datetime.strptime(s.strip(), "%Y/%m/%d %H:%M")
    except:
        pass
    try:
        dt = datetime.strptime(s.strip(), "%m/%d %H:%M")
        return dt.replace(year=datetime.now().year)
    except:
        return None

# âœ… å„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ã‚’å‡¦ç†
for source in SOURCE_ORDER:
    try:
        ws = source_book.worksheet(source)
        all_data = ws.get_all_values()
    except Exception as e:
        print(f"âš ï¸ ã‚·ãƒ¼ãƒˆ '{source}' èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        continue

    print(f"ğŸ“¥ {source}: {len(all_data)-1}ä»¶ã®ãƒ‡ãƒ¼ã‚¿è¡Œã‚’å‡¦ç†ä¸­...")

    source_count = 0
    skipped = 0

    for row in all_data[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤ã
        if len(row) < 4:
            skipped += 1
            continue
        dt = parse_datetime(row[2])
        if dt and yesterday_15 <= dt < today_15:
            all_rows.append([source] + row[:4])  # A:ãƒ‹ãƒ¥ãƒ¼ã‚¹å…ƒ, Bã€œE:ã‚¿ã‚¤ãƒˆãƒ«/URL/æŠ•ç¨¿æ—¥æ™‚/ã‚½ãƒ¼ã‚¹
            source_count += 1
        else:
            skipped += 1

    print(f"âœ… {source}: è²¼ä»˜ {source_count} ä»¶ / ã‚¹ã‚­ãƒƒãƒ— {skipped} ä»¶")

# âœ… ä¸€æ‹¬è²¼ä»˜ã‘ï¼ˆA2ã€œï¼‰
if all_rows:
    target_ws.update(values=all_rows, range_name="A2")
    print(f"âœ… åˆè¨ˆ {len(all_rows)} ä»¶ã‚’è²¼ã‚Šä»˜ã‘ã¾ã—ãŸã€‚")
else:
    print("âš ï¸ è©²å½“æœŸé–“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
