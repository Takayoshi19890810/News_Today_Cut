import os
import json
import re
from datetime import datetime, timedelta
import gspread

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆè¨­å®š
SOURCE_SPREADSHEET_ID = "1RglATeTbLU1SqlfXnNToJqhXLdNoHCdePldioKDQgU8"
TARGET_SPREADSHEET_ID = "1IYUuwzvlR2OJC8r3FkaUvA44tc0XGqT2kxbAXiMgt2s"
SOURCE_SHEETS = ["Google", "Yahoo", "MSN"]
NEWS_SOURCES = {"Google": "Google", "Yahoo": "Yahoo", "MSN": "MSN"}
DATE_COLUMN_INDEX = 2  # Cåˆ—ã€ŒæŠ•ç¨¿æ—¥ã€åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0å§‹ã¾ã‚Šï¼‰

def extract_articles(gc):
    sh = gc.open_by_key(SOURCE_SPREADSHEET_ID)
    now = datetime.now()
    today_15 = datetime(now.year, now.month, now.day, 15, 0)
    yesterday_15 = today_15 - timedelta(days=1)

    extracted = []
    for sheet in SOURCE_SHEETS:
        try:
            ws = sh.worksheet(sheet)
            values = ws.get_all_values()
            if not values:
                continue
            rows = values[1:]

            for row in rows:
                try:
                    date_str = row[DATE_COLUMN_INDEX].strip()

                    # Yahooå½¢å¼: å¹´ç„¡ã— + æ™‚åˆ» â†’ å¹´è£œå®Œ
                    if re.match(r"^\d{1,2}/\d{1,2} \d{1,2}:\d{2}$", date_str):
                        date_str = f"{now.year}/{date_str}"

                    # MSNå½¢å¼1: æœˆ/æ—¥ï¼ˆ6/10ï¼‰â†’ å¹´ã¨00:00æ™‚åˆ»è£œå®Œ
                    elif re.match(r"^\d{1,2}/\d{1,2}$", date_str):
                        date_str = f"{now.year}/{date_str} 00:00"

                    # MSNå½¢å¼2: å¹´/æœˆ/æ—¥ï¼ˆ2025/6/10ï¼‰â†’ æ™‚åˆ»è£œå®Œ
                    elif re.match(r"^\d{4}/\d{1,2}/\d{1,2}$", date_str):
                        date_str = f"{date_str} 00:00"

                    dt = datetime.strptime(date_str, "%Y/%m/%d %H:%M")

                    if yesterday_15 <= dt < today_15:
                        # A:ãƒ‹ãƒ¥ãƒ¼ã‚¹å…ƒ / B:ã‚¿ã‚¤ãƒˆãƒ« / C:URL / D:æŠ•ç¨¿æ—¥ / E:å¼•ç”¨å…ƒ
                        extracted.append([
                            NEWS_SOURCES[sheet],  # Aåˆ—: ãƒ‹ãƒ¥ãƒ¼ã‚¹å…ƒ
                            row[0],               # Båˆ—: ã‚¿ã‚¤ãƒˆãƒ«
                            row[1],               # Cåˆ—: URL
                            date_str,             # Dåˆ—: æŠ•ç¨¿æ—¥
                            row[3] if len(row) > 3 else ""  # Eåˆ—: å¼•ç”¨å…ƒ
                        ])
                except Exception as e:
                    print(f"âš ï¸ {sheet} ã‚¹ã‚­ãƒƒãƒ—: {row[DATE_COLUMN_INDEX]} â†’ {e}")
                    continue
        except Exception as e:
            print(f"âŒ {sheet} èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            continue

    headers = ["ãƒ‹ãƒ¥ãƒ¼ã‚¹å…ƒ", "ã‚¿ã‚¤ãƒˆãƒ«", "URL", "æŠ•ç¨¿æ—¥", "å¼•ç”¨å…ƒ"]
    return headers, extracted

def overwrite_sheet(gc, sheet_name, headers, data):
    sh = gc.open_by_key(TARGET_SPREADSHEET_ID)

    try:
        ws_existing = sh.worksheet(sheet_name)
        sh.del_worksheet(ws_existing)
        print(f"ğŸ—‘ ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
    except:
        pass

    ws = sh.add_worksheet(title=sheet_name, rows="100", cols=str(len(headers)))
    ws.append_row(headers)

    if data:
        ws.append_rows(data, value_input_option='USER_ENTERED')
        print(f"âœ… {len(data)} ä»¶ã‚’ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã«å‡ºåŠ›ã—ã¾ã—ãŸã€‚")
    else:
        print("âš ï¸ å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

def main():
    credentials = json.loads(os.environ["GCP_SERVICE_ACCOUNT_KEY"])
    gc = gspread.service_account_from_dict(credentials)
    headers, data = extract_articles(gc)
    sheet_name = datetime.now().strftime("%y%m%d")  # ä¾‹: 250610
    overwrite_sheet(gc, sheet_name, headers, data)

if __name__ == "__main__":
    main()
